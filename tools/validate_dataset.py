"""
æ•°æ®é›†éªŒè¯å·¥å…·
Validate dataset quality and completeness

ç”¨æ³•:
    python tools/validate_dataset.py --data_dir data/samples/inductor/normal
    python tools/validate_dataset.py --data_dir data/samples/inductor --recursive
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Tuple
import cv2
import numpy as np
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.utils.common import setup_logger

logger = setup_logger(__name__)


class DatasetValidator:
    """æ•°æ®é›†éªŒè¯å™¨"""
    
    # è´¨é‡æ ‡å‡†
    MIN_RESOLUTION = (640, 480)  # æœ€å°åˆ†è¾¨ç‡
    MAX_FILE_SIZE_MB = 10  # æœ€å¤§æ–‡ä»¶å¤§å°
    MIN_FILE_SIZE_KB = 50  # æœ€å°æ–‡ä»¶å¤§å°ï¼ˆé˜²æ­¢ç©ºæ–‡ä»¶ï¼‰
    
    # è§†è§’å…³é”®è¯
    VIEW_KEYWORDS = {
        'æ­£é¢': ['æ­£é¢', 'front', 'view1'],
        'åº•é¢': ['åº•é¢', 'bottom', 'view2'],
        'å‰ä¾§é¢': ['å‰ä¾§é¢', 'front_side', 'view3'],
        'åä¾§é¢': ['åä¾§é¢', 'back_side', 'view4'],
        'å·¦ä¾§é¢': ['å·¦ä¾§é¢', 'left', 'view5'],
        'å³ä¾§é¢': ['å³ä¾§é¢', 'right', 'view6'],
    }
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.issues = []
        self.warnings = []
        self.stats = {
            'total_samples': 0,
            'complete_samples': 0,
            'incomplete_samples': 0,
            'total_images': 0,
            'quality_issues': 0,
        }
    
    def find_sample_groups(self) -> Dict[str, Dict[str, Path]]:
        """
        æŸ¥æ‰¾æ ·æœ¬ç»„ï¼ˆæ¯ç»„åº”è¯¥æœ‰6ä¸ªè§†è§’ï¼‰
        
        Returns:
            {sample_id: {view_name: image_path}}
        """
        groups = defaultdict(dict)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å­æ–‡ä»¶å¤¹ç»„ç»‡
        subdirs = [d for d in self.data_dir.iterdir() if d.is_dir()]
        
        if subdirs:
            # æŒ‰æ–‡ä»¶å¤¹ç»„ç»‡
            for subdir in subdirs:
                sample_id = subdir.name
                for img_file in subdir.glob('*.*'):
                    if img_file.suffix.lower() in ['.bmp', '.png', '.jpg', '.jpeg']:
                        view_name = self._identify_view(img_file.stem)
                        if view_name:
                            groups[sample_id][view_name] = img_file
        else:
            # æŒ‰æ–‡ä»¶åå‰ç¼€ç»„ç»‡
            image_files = []
            for ext in ['.bmp', '.png', '.jpg', '.jpeg']:
                image_files.extend(self.data_dir.glob(f'*{ext}'))
            
            # åˆ†ç»„
            prefix_groups = defaultdict(list)
            for img_file in image_files:
                # æå–å‰ç¼€
                parts = img_file.stem.split('_')
                if len(parts) >= 2:
                    # å‡è®¾æ ¼å¼: prefix_view æˆ– prefix_id_view
                    prefix = '_'.join(parts[:-1])
                    prefix_groups[prefix].append(img_file)
            
            # è½¬æ¢ä¸ºviewå­—å…¸
            for prefix, files in prefix_groups.items():
                for file in files:
                    view_name = self._identify_view(file.stem)
                    if view_name:
                        groups[prefix][view_name] = file
        
        return dict(groups)
    
    def _identify_view(self, filename: str) -> str:
        """è¯†åˆ«è§†è§’åç§°"""
        filename_lower = filename.lower()
        for view_name, keywords in self.VIEW_KEYWORDS.items():
            for keyword in keywords:
                if keyword in filename_lower:
                    return view_name
        return None
    
    def check_completeness(self, groups: Dict) -> List[Dict]:
        """æ£€æŸ¥6è§†è§’å®Œæ•´æ€§"""
        results = []
        
        for sample_id, views in groups.items():
            result = {
                'sample_id': sample_id,
                'num_views': len(views),
                'missing_views': [],
                'is_complete': False,
            }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¨éƒ¨6ä¸ªè§†è§’
            expected_views = set(self.VIEW_KEYWORDS.keys())
            actual_views = set(views.keys())
            missing = expected_views - actual_views
            
            result['missing_views'] = list(missing)
            result['is_complete'] = len(missing) == 0
            
            if not result['is_complete']:
                self.warnings.append(
                    f"æ ·æœ¬ {sample_id} ä¸å®Œæ•´: ç¼ºå°‘ {', '.join(missing)}"
                )
                self.stats['incomplete_samples'] += 1
            else:
                self.stats['complete_samples'] += 1
            
            results.append(result)
            self.stats['total_samples'] += 1
        
        return results
    
    def check_image_quality(self, image_path: Path) -> Tuple[bool, List[str]]:
        """
        æ£€æŸ¥å•å¼ å›¾åƒè´¨é‡
        
        Returns:
            (is_valid, issues)
        """
        issues = []
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size_mb = image_path.stat().st_size / (1024 * 1024)
        file_size_kb = image_path.stat().st_size / 1024
        
        if file_size_mb > self.MAX_FILE_SIZE_MB:
            issues.append(f"æ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MB")
        
        if file_size_kb < self.MIN_FILE_SIZE_KB:
            issues.append(f"æ–‡ä»¶è¿‡å°: {file_size_kb:.2f}KBï¼ˆå¯èƒ½æ˜¯ç©ºæ–‡ä»¶ï¼‰")
        
        # å°è¯•åŠ è½½å›¾åƒ
        try:
            img = cv2.imread(str(image_path))
            if img is None:
                issues.append("æ— æ³•è¯»å–å›¾åƒ")
                return False, issues
            
            h, w = img.shape[:2]
            
            # æ£€æŸ¥åˆ†è¾¨ç‡
            if w < self.MIN_RESOLUTION[0] or h < self.MIN_RESOLUTION[1]:
                issues.append(f"åˆ†è¾¨ç‡è¿‡ä½: {w}x{h}")
            
            # æ£€æŸ¥æ›å…‰ï¼ˆç®€å•æ£€æŸ¥å¹³å‡äº®åº¦ï¼‰
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            mean_brightness = np.mean(gray)
            
            if mean_brightness < 30:
                issues.append(f"å›¾åƒè¿‡æš—: å¹³å‡äº®åº¦={mean_brightness:.1f}")
            elif mean_brightness > 225:
                issues.append(f"å›¾åƒè¿‡äº®: å¹³å‡äº®åº¦={mean_brightness:.1f}")
            
            # æ£€æŸ¥æ¨¡ç³Šï¼ˆLaplacianæ–¹å·®ï¼‰
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            blur_score = np.var(laplacian)
            
            if blur_score < 50:  # é˜ˆå€¼éœ€è¦æ ¹æ®å®é™…è°ƒæ•´
                issues.append(f"å¯èƒ½æ¨¡ç³Š: blur_score={blur_score:.1f}")
            
        except Exception as e:
            issues.append(f"å¤„ç†é”™è¯¯: {str(e)}")
            return False, issues
        
        return len(issues) == 0, issues
    
    def validate_all(self, groups: Dict) -> Dict:
        """éªŒè¯æ‰€æœ‰æ ·æœ¬"""
        validation_results = {
            'samples': [],
            'quality_report': {},
        }
        
        for sample_id, views in groups.items():
            sample_result = {
                'sample_id': sample_id,
                'views': {},
                'all_valid': True,
            }
            
            for view_name, image_path in views.items():
                is_valid, issues = self.check_image_quality(image_path)
                
                sample_result['views'][view_name] = {
                    'path': str(image_path),
                    'valid': is_valid,
                    'issues': issues,
                }
                
                if not is_valid:
                    sample_result['all_valid'] = False
                    self.stats['quality_issues'] += 1
                    self.issues.append(
                        f"{sample_id}/{view_name}: {', '.join(issues)}"
                    )
                
                self.stats['total_images'] += 1
            
            validation_results['samples'].append(sample_result)
        
        return validation_results
    
    def generate_report(self) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = []
        report.append("=" * 70)
        report.append("æ•°æ®é›†éªŒè¯æŠ¥å‘Š")
        report.append("=" * 70)
        report.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        report.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        report.append(f"  æ€»æ ·æœ¬æ•°: {self.stats['total_samples']}")
        report.append(f"  å®Œæ•´æ ·æœ¬æ•° (6è§†è§’): {self.stats['complete_samples']} âœ“")
        report.append(f"  ä¸å®Œæ•´æ ·æœ¬æ•°: {self.stats['incomplete_samples']}")
        report.append(f"  æ€»å›¾åƒæ•°: {self.stats['total_images']}")
        report.append(f"  è´¨é‡é—®é¢˜æ•°: {self.stats['quality_issues']}")
        report.append("")
        
        # å®Œæ•´æ€§è¯„ä¼°
        if self.stats['total_samples'] > 0:
            completeness = self.stats['complete_samples'] / self.stats['total_samples'] * 100
            report.append(f"ğŸ“ˆ å®Œæ•´æ€§: {completeness:.1f}%")
            
            if completeness == 100:
                report.append("  âœ… æ‰€æœ‰æ ·æœ¬éƒ½æœ‰å®Œæ•´çš„6è§†è§’ï¼")
            elif completeness >= 80:
                report.append("  âš ï¸  å¤§éƒ¨åˆ†æ ·æœ¬å®Œæ•´ï¼Œä½†ä»æœ‰ç¼ºå¤±")
            else:
                report.append("  âŒ æ•°æ®å®Œæ•´æ€§è¾ƒå·®ï¼Œéœ€è¦è¡¥å……")
        report.append("")
        
        # è´¨é‡è¯„ä¼°
        if self.stats['total_images'] > 0:
            quality_rate = (self.stats['total_images'] - self.stats['quality_issues']) / self.stats['total_images'] * 100
            report.append(f"ğŸ¯ è´¨é‡åˆæ ¼ç‡: {quality_rate:.1f}%")
            
            if quality_rate >= 95:
                report.append("  âœ… å›¾åƒè´¨é‡ä¼˜ç§€ï¼")
            elif quality_rate >= 80:
                report.append("  âš ï¸  è´¨é‡è‰¯å¥½ï¼Œä½†æœ‰éƒ¨åˆ†é—®é¢˜éœ€è¦ä¿®å¤")
            else:
                report.append("  âŒ è´¨é‡é—®é¢˜è¾ƒå¤šï¼Œå»ºè®®é‡æ–°é‡‡é›†")
        report.append("")
        
        # è­¦å‘Šä¿¡æ¯
        if self.warnings:
            report.append("âš ï¸  è­¦å‘Šä¿¡æ¯:")
            for warning in self.warnings[:10]:  # æœ€å¤šæ˜¾ç¤º10æ¡
                report.append(f"  - {warning}")
            if len(self.warnings) > 10:
                report.append(f"  ... è¿˜æœ‰ {len(self.warnings) - 10} æ¡è­¦å‘Š")
            report.append("")
        
        # ä¸¥é‡é—®é¢˜
        if self.issues:
            report.append("âŒ è´¨é‡é—®é¢˜:")
            for issue in self.issues[:10]:  # æœ€å¤šæ˜¾ç¤º10æ¡
                report.append(f"  - {issue}")
            if len(self.issues) > 10:
                report.append(f"  ... è¿˜æœ‰ {len(self.issues) - 10} ä¸ªé—®é¢˜")
            report.append("")
        
        # æ€»ç»“
        report.append("=" * 70)
        report.append("ğŸ“Œ æ€»ç»“:")
        
        if self.stats['complete_samples'] >= 50 and self.stats['quality_issues'] < 10:
            report.append("  âœ… æ•°æ®é›†è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")
        elif self.stats['complete_samples'] >= 20:
            report.append("  âš ï¸  æ•°æ®é›†åŸºæœ¬å¯ç”¨ï¼Œä½†å»ºè®®ç»§ç»­é‡‡é›†")
        else:
            report.append("  âŒ æ•°æ®é›†ä¸è¶³ï¼Œéœ€è¦ç»§ç»­é‡‡é›†")
        
        report.append("=" * 70)
        
        return '\n'.join(report)


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®é›†éªŒè¯å·¥å…·')
    parser.add_argument('--data_dir', type=str, required=True,
                        help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--output', type=str, default=None,
                        help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--recursive', action='store_true',
                        help='é€’å½’æ£€æŸ¥å­ç›®å½•')
    
    args = parser.parse_args()
    
    data_dir = Path(args.data_dir)
    if not data_dir.exists():
        logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    logger.info(f"å¼€å§‹éªŒè¯æ•°æ®é›†: {data_dir}")
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = DatasetValidator(data_dir)
    
    # æŸ¥æ‰¾æ ·æœ¬ç»„
    groups = validator.find_sample_groups()
    logger.info(f"æ‰¾åˆ° {len(groups)} ä¸ªæ ·æœ¬ç»„")
    
    if not groups:
        logger.error("æœªæ‰¾åˆ°ä»»ä½•æ ·æœ¬ï¼è¯·æ£€æŸ¥æ•°æ®ç›®å½•å’Œæ–‡ä»¶å‘½åã€‚")
        return
    
    # æ£€æŸ¥å®Œæ•´æ€§
    completeness_results = validator.check_completeness(groups)
    
    # éªŒè¯è´¨é‡
    validation_results = validator.validate_all(groups)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = validator.generate_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    if args.output:
        output_path = Path(args.output)
        output_path.write_text(report, encoding='utf-8')
        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


if __name__ == '__main__':
    main()
